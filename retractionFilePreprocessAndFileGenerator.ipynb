{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9cd66e",
   "metadata": {},
   "source": [
    "### This notebook reads original paper from text document and creates a csv file containing processed retracted and non-retracted paper text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc37053",
   "metadata": {},
   "source": [
    "## Importing pandas, nltk, and python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60563f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200e269",
   "metadata": {},
   "source": [
    "#### Below methods are used to retrieve files in numerical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787d2c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e63c154",
   "metadata": {},
   "source": [
    "#### Stopwords and markdown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6245b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4651aa3b",
   "metadata": {},
   "source": [
    "#### Using below script to remove punctuations, stopwords, hyperlinks. Also performing lemmatization and stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d139b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message(message):\n",
    "    '''\n",
    "    Input:\n",
    "        message: a string containing a message.\n",
    "    Output:\n",
    "        messages_cleaned: a list of words containing the processed message.\n",
    "\n",
    "    '''\n",
    "    message = message.lower()\n",
    "    message = re.sub(r\"http\\S+\", \"\", message)\n",
    "    message = re.sub(r\"www.\\S+\", \"\", message)\n",
    "    messages_links_removed = \"\".join([char for char in message if char not in string.punctuation])\n",
    "    messages_cleaned = \" \".join([word for word in re.split('\\W+', messages_links_removed)\n",
    "                                 if word not in stopword])\n",
    "    # text = \" \".join([ps.stem(word) for word in re.split('\\W+', messages_cleaned)])\n",
    "    # text = \" \".join([word for word in re.split('\\W+', messages_cleaned)])\n",
    "    return messages_cleaned\n",
    "\n",
    "\n",
    "os.chdir(r'Retracted_Data')\n",
    "retractionNumArr = glob.glob('*.txt')\n",
    "retractionNumArr.sort(key=natural_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f607c91",
   "metadata": {},
   "source": [
    "### Changing the directory to all text files of scientific/research paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b635f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'..')\n",
    "os.chdir(r'Retracted_Data')\n",
    "retractionNumArr = glob.glob('*.txt')\n",
    "retractionNumArr.sort(key=natural_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008ffcc",
   "metadata": {},
   "source": [
    "### Below script first text files and then performs prepocessing on text and return an array of preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e533e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndPreprocessText():\n",
    "    paperTextArr = []\n",
    "    retractedPaperTextArr = []\n",
    "    finalRetractedPaperTextArr = []\n",
    "    for file in retractionNumArr:\n",
    "        i = 0\n",
    "        if file.endswith(\".txt\"):\n",
    "            paperText = ''\n",
    "            with io.open(file, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "                    io.open('../Retracted_Data_parsed.txt', 'w', encoding='ascii', errors='ignore') as outfile:\n",
    "                for line in infile:\n",
    "                    if i != 0:\n",
    "                        paperText = paperText + \" \" + line\n",
    "                    i = i + 1\n",
    "            retractedPaperTextArr.append(paperText)\n",
    "\n",
    "    for i in range(0, len(retractedPaperTextArr)):\n",
    "        retractedPaperTextArr[i] = re.sub('-[\\n]+', \"\", retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub('-', \" \", retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub('[\\n]+', \" \", retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub(r'\\s\\s+', \" \", retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub(\n",
    "            r'After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE\\S*',\n",
    "            \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r'Publication Principles.\\S*', \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(\n",
    "            r\"We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.\\S*\",\n",
    "            \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(\n",
    "            r\"TTon by contacting TPII@ieee.org.\\S*\",\n",
    "            \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r'\\w*\\d\\w*', '', retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub(r\"retract\\S*\", \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r\"RETRACT\\S*\", \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r\"notice\\S+\", \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r'\\b\\d+\\b', \"\", retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub(r'\\s\\s+', \" \", retractedPaperTextArr[i])\n",
    "        referenceIndex = retractedPaperTextArr[i].rfind(\"references\")\n",
    "        if referenceIndex != -1:\n",
    "            retractedPaperTextArr[i] = retractedPaperTextArr[i][:referenceIndex]\n",
    "        final_message = clean_message(retractedPaperTextArr[i])\n",
    "        if len(final_message) == 0:\n",
    "            print(i)\n",
    "        finalRetractedPaperTextArr.append(final_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c969981a",
   "metadata": {},
   "source": [
    "### Read the list of retraction reason and store in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f29506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndPreprocessReason():\n",
    "    os.chdir(r'..')\n",
    "    retractionReason = ''\n",
    "    with open('RetractionReason/RRList.txt') as f:\n",
    "        retractionReason = f.read()\n",
    "    retractionReasonArr = retractionReason.splitlines()\n",
    "\n",
    "    rSet = list()\n",
    "    for i in range(0, len(retractionReasonArr)):\n",
    "        text = retractionReasonArr[i]\n",
    "        textArr = text.split(',')\n",
    "        for j in range(0, len(textArr)):\n",
    "            p = textArr[j].replace('+', '')\n",
    "            if p not in rSet and p != '':\n",
    "                rSet.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768d22a",
   "metadata": {},
   "source": [
    "### Combine retraction reason and associated text. Create csv file having both retracted and non-retracted papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'RetractedReasonData')\n",
    "\n",
    "for i in range(0, len(rSet)):\n",
    "    reasonArr = []\n",
    "    finalRetractedPaperTextArr1 = []\n",
    "    for j in range(0, len(retractionReasonArr)):\n",
    "        if len(finalRetractedPaperTextArr[j]) > 0:\n",
    "            if rSet[i] in retractionReasonArr[j]:\n",
    "                reasonArr.append(1)\n",
    "            else:\n",
    "                reasonArr.append(0)\n",
    "            finalRetractedPaperTextArr1.append(finalRetractedPaperTextArr[j])\n",
    "    list_of_tuples = list(zip(reasonArr, finalRetractedPaperTextArr1))\n",
    "    df = pd.DataFrame(list_of_tuples, columns=['Target', 'Text'])\n",
    "    fName = rSet[i].replace(' ','').replace('/','')\n",
    "    df.to_csv('retraction'+'By'+ fName +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28a1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
