{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e4d5888",
   "metadata": {},
   "source": [
    "### This notebook reads original paper from text document and creates a csv file containing processed retracted and non-retracted paper text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ec2f0",
   "metadata": {},
   "source": [
    "## Importing pandas, nltk, and python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b68e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.utils import resample\n",
    "import string\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964aca85",
   "metadata": {},
   "source": [
    "#### Below methods are used to retrieve files in numerical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05aa083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1728d4",
   "metadata": {},
   "source": [
    "#### Stopwords and markdown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf1b79",
   "metadata": {},
   "source": [
    "#### Using below script to remove punctuations, stopwords, hyperlinks. Also performing lemmatization and stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message(message):\n",
    "    '''\n",
    "    Input:\n",
    "        message: a string containing a message.\n",
    "    Output:\n",
    "        messages_cleaned: a list of words containing the processed message.\n",
    "\n",
    "    '''\n",
    "    message = message.lower()\n",
    "    message = re.sub(r\"http\\S+\", \"\", message)\n",
    "    message = re.sub(r\"www.\\S+\", \"\", message)\n",
    "    messages_links_removed = \"\".join([char for char in message if char not in string.punctuation])\n",
    "    messages_cleaned = \" \".join([word for word in re.split('\\W+', messages_links_removed)\n",
    "                                 if word not in stopword])\n",
    "    # text = \" \".join([ps.stem(word) for word in re.split('\\W+', messages_cleaned)])\n",
    "    # text = \" \".join([word for word in re.split('\\W+', messages_cleaned)])\n",
    "    return messages_cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d4f45",
   "metadata": {},
   "source": [
    "### Changing the directory to read all text files of scientific/research paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f409857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'..')\n",
    "os.chdir(r'Retracted_Data')\n",
    "retractionNumArr = glob.glob('*.txt')\n",
    "retractionNumArr.sort(key=natural_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2839c",
   "metadata": {},
   "source": [
    "### Below script read retracted files and then performs prepocessing on text and return an array of preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndPreprocessText():\n",
    "    retractedPaperTextArr = []\n",
    "    finalRetractedPaperTextArr = []\n",
    "\n",
    "    for file in retractionNumArr:\n",
    "        i = 0\n",
    "        if file.endswith(\".txt\"):\n",
    "            paperText = ''\n",
    "            with io.open(file, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "                    io.open('../Retracted_Data_parsed.txt', 'w', encoding='ascii', errors='ignore') as outfile:\n",
    "                for line in infile:\n",
    "                    if i != 0:\n",
    "                        paperText = paperText + \" \" + line\n",
    "                    i = i + 1\n",
    "            retractedPaperTextArr.append(paperText)\n",
    "\n",
    "    for i in range(0, len(retractedPaperTextArr)):\n",
    "        retractedPaperTextArr[i] = re.sub('-[\\n]+', \"\", retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub('-', \" \", retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub('[\\n]+', \" \", retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub(r'\\s\\s+', \" \", retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub(r'After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE\\S*', \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r'Publication Principles.\\S*', \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r\"We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.\\S*\", \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r\"The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.\\S*\", \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r'\\w*\\d\\w*', '', retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub(r\"retract\\S*\", \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r\"RETRACT\\S*\", \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r\"notice\\S+\", \"\", retractedPaperTextArr[i], flags=re.S | re.I)\n",
    "        retractedPaperTextArr[i] = re.sub(r'\\b\\d+\\b', \"\", retractedPaperTextArr[i])\n",
    "        retractedPaperTextArr[i] = re.sub(r'\\s\\s+', \" \", retractedPaperTextArr[i])\n",
    "        referenceIndex = retractedPaperTextArr[i].rfind(\"references\")\n",
    "        if referenceIndex != -1:\n",
    "            retractedPaperTextArr[i] = retractedPaperTextArr[i][:referenceIndex]\n",
    "        final_message = clean_message(retractedPaperTextArr[i])\n",
    "        if len(final_message) > 0:\n",
    "            finalRetractedPaperTextArr.append(final_message)\n",
    "    retractedArr = []\n",
    "    for i in range(0, len(finalRetractedPaperTextArr)):\n",
    "        retractedArr.append(1)\n",
    "    list_of_RetractedTuples = list(zip(retractedArr, finalRetractedPaperTextArr))\n",
    "    return list_of_RetractedTuples\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebfdb30",
   "metadata": {},
   "source": [
    "#### Change directory for Non-Retracted paper collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'..')\n",
    "os.chdir(r'Non_Retracted')\n",
    "nonRetractionNumArr = glob.glob('*.txt')\n",
    "nonRetractionNumArr.sort(key=natural_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa1e6e",
   "metadata": {},
   "source": [
    "### Below script read non-retracted files and then performs prepocessing on text and return an array of preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2cf624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readNonRetractedPaper:\n",
    "    nonRetractedPaperTextArr = []\n",
    "    finalNonRetractedPaperTextArr = []\n",
    "    for file in nonRetractionNumArr:\n",
    "        if file.endswith(\".txt\"):\n",
    "            paperText = ''\n",
    "            with io.open(file, 'r', encoding='utf-8', errors='ignore') as infile, \\\n",
    "                    io.open('../NonRetracted_Data_parsed.txt', 'w', encoding='ascii', errors='ignore') as outfile:\n",
    "                for line in infile:\n",
    "                    paperText = paperText + \" \" + line\n",
    "            nonRetractedPaperTextArr.append(paperText)\n",
    "\n",
    "    for i in range(0, len(nonRetractedPaperTextArr)):\n",
    "        nonRetractedPaperTextArr[i] = re.sub('-[\\n]+', \"\", nonRetractedPaperTextArr[i])\n",
    "        nonRetractedPaperTextArr[i] = re.sub('-', \" \", nonRetractedPaperTextArr[i])\n",
    "        nonRetractedPaperTextArr[i] = re.sub('[\\n]+', \" \", nonRetractedPaperTextArr[i])\n",
    "        nonRetractedPaperTextArr[i] = re.sub(r'\\w*\\d\\w*', '', nonRetractedPaperTextArr[i])\n",
    "       # nonRetractedPaperTextArr[i] = re.sub(r\"retract\\S+\", \"\", nonRetractedPaperTextArr[i])\n",
    "       # nonRetractedPaperTextArr[i] = re.sub(r\"RETRACT\\S+\", \"\", nonRetractedPaperTextArr[i])\n",
    "        nonRetractedPaperTextArr[i] = re.sub(r'\\b\\d+\\b', \"\", nonRetractedPaperTextArr[i])\n",
    "        nonRetractedPaperTextArr[i] = re.sub(r'\\s\\s+', \" \", nonRetractedPaperTextArr[i])\n",
    "        nonRetractedPaperTextArr[i] = nonRetractedPaperTextArr[i][:nonRetractedPaperTextArr[i].rfind(\"references\")]\n",
    "        referenceIndex = nonRetractedPaperTextArr[i].rfind(\"references\")\n",
    "        if referenceIndex != -1:\n",
    "            nonRetractedPaperTextArr[i] = nonRetractedPaperTextArr[i][:referenceIndex]\n",
    "        final_message = clean_message(nonRetractedPaperTextArr[i])\n",
    "        if len(final_message) > 0:\n",
    "            finalNonRetractedPaperTextArr.append(final_message)\n",
    "    nonRetractedArr = []\n",
    "    for i in range(0, len(finalNonRetractedPaperTextArr)):\n",
    "        nonRetractedArr.append(0)\n",
    "\n",
    "    list_of_NonRetractedTuples = list(zip(nonRetractedArr, finalNonRetractedPaperTextArr))\n",
    "    nonRetractedTuple1 = list_of_NonRetractedTuples[0: len(retractedArr)]\n",
    "    nonRetractedTuple2 = list_of_NonRetractedTuples[len(retractedArr):2*len(retractedArr)]\n",
    "    nonRetractedTuple3 = list_of_NonRetractedTuples[2*len(retractedArr):3*len(retractedArr)]\n",
    "    nonRetractedTuple4 = list_of_NonRetractedTuples[3*len(retractedArr):]\n",
    "    return list_of_NonRetractedTuples, nonRetractedTuple1, nonRetractedTuple2, nonRetractedTuple3, nonRetractedTuple4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac62f78",
   "metadata": {},
   "source": [
    "#### Append retracted and non-retracted papers in a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ddd1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_NonRetractedTuples, nonRetractedTuple1, nonRetractedTuple2, nonRetractedTuple3, nonRetractedTuple4 = readNonRetractedPaper()\n",
    "os.chdir(r'..')\n",
    "t1 = list_of_RetractedTuples.copy()\n",
    "for elem in nonRetractedTuple1:\n",
    "    t1.append(elem)\n",
    "\n",
    "t2 = list_of_RetractedTuples.copy()\n",
    "for elem in nonRetractedTuple2:\n",
    "    t2.append(elem)\n",
    "\n",
    "t3 = list_of_RetractedTuples.copy()\n",
    "for elem in nonRetractedTuple3:\n",
    "    t3.append(elem)\n",
    "\n",
    "t4 = list_of_RetractedTuples.copy()\n",
    "for elem in nonRetractedTuple4:\n",
    "    t4.append(elem)\n",
    "\n",
    "df = pd.DataFrame(t1, columns=['Target', 'Text'])\n",
    "df.to_csv('retraction1.csv')\n",
    "df = pd.DataFrame(t2, columns=['Target', 'Text'])\n",
    "df.to_csv('retraction2.csv')\n",
    "df = pd.DataFrame(t3, columns=['Target', 'Text'])\n",
    "df.to_csv('retraction3.csv')\n",
    "df = pd.DataFrame(t4, columns=['Target', 'Text'])\n",
    "df.to_csv('retraction4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
